---
title: "Some proofs about Statistical Learning and Label Noise"
---

When doing binary classfication, having noise in our label means that they can be flipped from one class to the other. When observing a label, we will never know if it has been flipped or not, only the probability of the flip to occur.

Noisy labels can definitly mess up with model accuracy and make us unable to evaluate it. For example, answering this question can be quite hard : Is it a false positive or the algorithm was right and the label was flipped ?

Thanksfully researchers are clever and they found some theoritical guarantees to still be able to do machine learning in this setup. We will redo proofs found in various papers covering this subject, starting from the easiest setup (random noise) to the hardest one (individual dependent noise).

<!--truncate-->

## Notations

Firts, let's have some notations for the following proofs.

- Let $X âˆˆ \mathcal{X} âŠ‚ â„^d$, be the data
- Let $Y âˆˆ \mathcal{Y} = \{-1,+1\}$, be the true unobserved label
- Let $\tilde{Y} âˆˆ \mathcal{Y}$, be the observed labels
- Let $D(X,Y)$, be the clean distribution
- Let $D_Ï(X,\tilde{Y})$, be the noisy distribution
- Let $Ï_Y(X) = â„™(\tilde{Y}|Y,X)$, be the noise probability

## Random Noise

Having random noise in our labels means that the probability of a flip to occur is unrelated to the statsitical individual $X$ or from the label value $Y$.

#### Definition :

We say that our labels are under a random noise if there is $Ïâˆˆâ„$ so that $âˆ€Xâˆˆ\mathcal{X},âˆ€Yâˆˆ\mathcal{Y}, Ï_Y(X)=Ï$

#### Definition :

* Let $\mathcal{F} = \mathcal{X}^{\mathcal{Y}}$
* Let $Lâˆˆ\mathcal{Y^2}^{â„}$
* Let $câˆˆâ„$

We say that L is a symetric loss function when :

$$
âˆ€fâˆˆ\mathcal{F},âˆ€xâˆˆ\mathcal{X},âˆ‘_{yâˆˆ\mathcal{Y}}L(f(x),y)=c
$$

#### Theorem :

Let :
* $\mathcal{F} = \mathcal{X}^{\mathcal{Y}}$
* $Lâˆˆ\mathcal{Y^2}^{â„}$

If :
* $\mathcal{Y}=\{-1,1\}$
* $L$ is a symetric loss function
* $Ïâˆˆâ„$ and $Ï<min_{yâˆˆ\mathcal{Y}}(â„™(Y=y))$

Then $L$ is robust to random noise :
$$
\underset{fâˆˆ\mathcal{F}}{argmin}R_{D,L}(f)=\underset{fâˆˆ\mathcal{F}}{argmin}R_{D_Ï,L}(f)
$$

#### Proof :

1. First let's try to find a relation between $â„™(\tilde{Y}=1|X)$ and $â„™(Y=1|X)$ :

$$
\begin{aligned}
â„™(\tilde{Y}=1|X) &= â„™(\tilde{Y}=1,Y=1|X) + â„™(\tilde{Y}=1,Y=-1|X)\\
&= â„™(\tilde{Y}=1|Y=1,X)â„™(Y=1|X) + â„™(\tilde{Y}=1|Y=-1,X)â„™(Y=-1|X)\\
&= (1-â„™(\tilde{Y}=-1|Y=1,X))â„™(Y=1|X) + â„™(\tilde{Y}=1|Y=-1,X)â„™(Y=-1|X)\\
&= (1-Ï)â„™(Y=1|X) + Ïâ„™(Y=-1|X)\\
&= (1-Ï)â„™(Y=1|X) + Ï(1-â„™(Y=1|X))\\
&= (1-Ï-Ï)â„™(Y=1|X) + Ï\\
&= (1-2Ï)â„™(Y=1|X) + Ï\\
\end{aligned}
$$

2. So we have :

$$
\begin{aligned}
â„™(\tilde{Y}=-1|X) &= (1-2Ï)â„™(Y=-1|X) + Ï\\
\end{aligned}
$$

3. Now come back to the real question :

$$
\begin{aligned}
R_{D_Ï,L}(f) &= ğ”¼_{(X,\tilde{Y})âˆ¼D_Ï}[L(f(X),\tilde{Y})]\\
&= âˆ«_\mathcal{Y}âˆ«_\mathcal{X}L(f(X),\tilde{Y})â„™(\tilde{Y},X)dxdy\\
&= âˆ«_\mathcal{X}(â„™(\tilde{Y}=1,X)L(f(X),1)+â„™(\tilde{Y}=-1,X)L(f(X),-1))dx\\
&= âˆ«_\mathcal{X}(â„™(\tilde{Y}=1|X)â„™(X)L(f(X),1)+â„™(\tilde{Y}=-1|X)â„™(X)L(f(X),-1))dx\\
&= âˆ«_\mathcal{X}â„™(X)(â„™(\tilde{Y}=1|X)L(f(X),1)+â„™(\tilde{Y}=-1|X)L(f(X),-1))dx\\
&= âˆ«_\mathcal{X}â„™(X)(((1-2Ï)â„™(Y=1|X) + Ï)L(f(X),1)+((1-2Ï)â„™(Y=-1|X) + Ï)L(f(X),-1))dx\\
&= âˆ«_\mathcal{X} â„™(X)((1-2Ï)â„™(Y=1|X)L(f(X),1) + (1-2Ï)â„™(Y=-1|X)L(f(X),-1))dx + âˆ«_\mathcal{X} â„™(X)(ÏL(f(X),1) + ÏL(f(X),-1))dx\\
&= (1-2Ï)âˆ«_\mathcal{X} â„™(X)(â„™(Y=1|X)L(f(X),1) + â„™(Y=-1|X)L(f(X),-1))dx + Ïâˆ«_\mathcal{X} (L(f(X),1) + L(f(X),-1))â„™(X)dx\\
&= (1-2Ï)âˆ«_\mathcal{X} (â„™(Y=1|X)â„™(X)L(f(X),1) + â„™(Y=-1|X)â„™(X)L(f(X),-1))dx + Ïâˆ«_\mathcal{X} câ„™(X)dx\\
&= (1-2Ï)âˆ«_\mathcal{X} (â„™(Y=1,X)L(f(X),1) + â„™(Y=-1,X)L(f(X),-1))dx + Ïc\\
&= (1-2Ï) âˆ«_\mathcal{Y}âˆ«_\mathcal{X} â„™(Y,X)L(f(X),Y)dydx + Ïc\\
&= (1-2Ï) R_{D,L}(f) + Ïc\\
\end{aligned}
$$

#### Examples :

There is plenty of symmetric loss functions for binary classification that can be used :

* 0-1 loss
* unhinged loss
* sigmoid loss
* ramp loss

## Class Dependent Noise

As it sounds, class dependent noise means that the probability of label to be flipped is link to the value of the unobserved label.

#### Definition :

We say that our labels are under a class dependent noise if there is $(Ï_Y)_{Yâˆˆ\mathcal{Y}}âˆˆ[0,1]^{|\mathcal{Y}|}$ so that $âˆ€Xâˆˆ\mathcal{X},âˆ€Yâˆˆ\mathcal{Y}, Ï_Y(X)=Ï_Y$

#### Theorem :

Let :
* $\mathcal{F} = \mathcal{X}^{\mathcal{Y}}$
* $\mathcal{L}=\mathcal{Y^2}^{â„}$

If :

* Our labels are under a class dependent noise.

Then :

$$
âˆ€Lâˆˆ\mathcal{L},âˆƒ\tilde{L}âˆˆ\mathcal{L},\underset{fâˆˆ\mathcal{F}}{argmin}R_{D,L}(f)=\underset{fâˆˆ\mathcal{F}}{argmin}R_{D_Ï,\tilde{L}}(f)
$$

#### Proof :

$$
\begin{aligned}
R_{D,L}(f) &= ğ”¼_{(X,Y)âˆ¼D}[L(f(X),Y)]\\
&= âˆ«_\mathcal{Y}âˆ«_\mathcal{X}â„™(X,Y)L(f(X),Y)dxdy\\
&= âˆ«_\mathcal{Y}âˆ«_\mathcal{X}â„™(X,\tilde{Y})\frac{â„™(X,Y)}{â„™(X,\tilde{Y})}L(f(X),Y)dxdy\\
&= ğ”¼_{(X,\tilde{Y})âˆ¼D_Ï}[\frac{â„™(X,Y)}{â„™(X,\tilde{Y})}L(f(X),Y)]\\
&= ğ”¼_{(X,\tilde{Y})âˆ¼D_Ï}[Î²(X,\tilde{Y})L(f(X),Y)]\\
&= ğ”¼_{(X,\tilde{Y})âˆ¼D_Ï}[\tilde{L}(f(X),\tilde{Y})]\\
&= R_{D_Ï,\tilde{L}}(f)\\
\end{aligned}
$$

#### Examples :

$$
\begin{aligned}
Î²(X,\tilde{Y})&=\frac{â„™(X,Y)}{â„™(X,\tilde{Y})}\\
&=\frac{â„™(Y|X)â„™(X)}{â„™(\tilde{Y}|X)â„™(X)}\\
&=\frac{â„™(Y|X)}{â„™(\tilde{Y}|X)}\\
\end{aligned}
$$

Reminder :

$$
\begin{aligned}
â„™(\tilde{Y}=-1|X) &= (1-Ï_{+1}-Ï_{-1})â„™(Y=-1|X) + Ï_{-1}\\ â„™(\tilde{Y}=+1|X) &= (1-Ï_{+1}-Ï_{-1})â„™(Y=-1|X) + Ï_{+1}\\
\end{aligned}
$$

So :

$$
\begin{aligned}
Î²(X,\tilde{Y}=y)&=\frac{\frac{â„™(\tilde{Y}=y|X)-Ï_{-y}}{1-Ï_{+1}-Ï_{-1}}}{â„™(\tilde{Y}=y|X)}\\
&=\frac{â„™(\tilde{Y}=y|X)-Ï_{-y}}{(1-Ï_{+1}-Ï_{-1})â„™(\tilde{Y}=y|X)}\\
\end{aligned}
$$

Now you only need to estimate $Ï_{+1}$ and $Ï_{-1}$ to be able to use your new loss robust to class dependant noise.
