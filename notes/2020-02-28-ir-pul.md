---
title: "Importance Reweighting for Positive Unlabelled Learning"
---

## Introduction

After redoing the proofs of "Classification with Noisy Labels by Importance Reweighting" by Liu and Tao, we thought that extending to Positive Unlabelled Learning could be quite trivial and useful.

### First let's remind us about the results of the paper

Let :
* $\mathcal{F} = \mathcal{X}^{\mathcal{Y}}$
* $\mathcal{L}=\mathcal{Y^2}^{ℝ}$

If :

* Our labels are under a class dependent noise, with $(ρ_y)_{y∈\mathcal{Y}}∈[0,1]^{|\mathcal{Y}|}$

Then :

$$
∀L∈\mathcal{L},∃\tilde{L}∈\mathcal{L},\underset{f∈\mathcal{F}}{argmin}R_{D,L}(f)=\underset{f∈\mathcal{F}}{argmin}R_{D_ρ,\tilde{L}}(f)
$$

With :

$$
\tilde{L}(f(X),Y) = β(X,\tilde{Y})L(f(X),Y)
$$
$$
β(X,\tilde{Y}=y)=\frac{ℙ(\tilde{Y}=y|X)-ρ_{-y}}{(1-ρ_{+1}-ρ_{-1})ℙ(\tilde{Y}=y|X)}
$$

### Second let's think about the links between Robust Label Learning (RLL) and Positive Unlabelled Learning (PUL)

Let's write the probability to see $\tilde{Y}=1$ and $\tilde{Y}=Missing$ in terms of the probability $Y=1$ and $Y=-1$ by definition of the propensity $e(x)$ :

$$
ℙ(\tilde{Y}=1|X=x) = e(x)ℙ(Y=1|X=x)
$$

$$
ℙ(\tilde{Y}=Missing) = (1-e(x))ℙ(Y=1|X=x) + ℙ(Y=-1|X=x)
$$

Let's annonate all $Missing$ as $-1$ and express the probability to see $\tilde{Y}=y$ conditionally to $Y=-y$

$$
\begin{aligned}
ℙ(\tilde{Y}=1|Y=-1,X=x) &= e(x)ℙ(Y=1|Y=-1,X=x)
&= 0
\end{aligned}
$$

$$
\begin{aligned}
ℙ(\tilde{Y}=-1|Y=1,X=x) &= (1-e(x))ℙ(Y=1|Y=1,X=x) + ℙ(Y=-1|Y=1,X=x)
&= 1-e(x)
\end{aligned}
$$

With this rewriting we showed that PUL is equivalent to RLL with an asymetric noise function which is null for one of the label and equal to 1 minus the propensity for the other label.

### Third adapt First with Second

The first result about Importance Reweighting for RLL only applies to a class dependent noise, so constant by instance. If we want to apply this result to PUL thanks to second point, it will only be valid for PUL with a constant propensity function.

So $∃e∈ℝ,∀x∈\mathcal{X},e(x)=e$ and $ρ_1=0$ and $ρ_{-1}=1-e$.

Let's calculate $β$ for PUL :

$$
\begin{aligned}
β(X,\tilde{Y}=1) &= \frac{ℙ(\tilde{Y}=1|X)-ρ_{-1}}{(1-ρ_{+1}-ρ_{-1})ℙ(\tilde{Y}=1|X)}\\
&= \frac{ℙ(\tilde{Y}=1|X)-(1-e)}{(1-(1-e))ℙ(\tilde{Y}=1|X)}\\
&= \frac{ℙ(\tilde{Y}=1|X)-(1-e)}{eℙ(\tilde{Y}=1|X)}\\
&= \frac{1}{e}-\frac{1-e}{eℙ(\tilde{Y}=1|X)}\\
&= \frac{1}{e}\left(1-\frac{1-e}{ℙ(\tilde{Y}=1|X)}\right)\\
\end{aligned}
$$

$$
\begin{aligned}
β(X,\tilde{Y}=-1) &= \frac{ℙ(\tilde{Y}=-1|X)-ρ_1}{(1-ρ_{+1}-ρ_{-1})ℙ(\tilde{Y}=-1|X)}\\
&= \frac{ℙ(\tilde{Y}=-1|X)}{(1-(1-e))ℙ(\tilde{Y}=-1|X)}\\
&= \frac{1}{e}\\
\end{aligned}
$$

In the PUL setting, we are able to express $β$ in function of the propensity $e$ instead of the noise probability functions $ρ_1$ and $ρ_{-1}$.

Now, if we want to adapt a loss function from the supervised setting to PUL by importance reweighting, we only need to estimate the propensity constant $e$.