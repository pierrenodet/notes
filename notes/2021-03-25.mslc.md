---
title: "Learning to Purify Noisy Labels via Meta Soft Label Corrector"
---

<p align="center">

![MSLC](/figures/mslc.png)

</p>

* **code** : https://github.com/WuYichen-97/Learning-to-Purify-Noisy-Labels-via-Meta-Soft-Label-Corrector
* **pdf** : https://arxiv.org/pdf/2008.00627.pdf

## Summary

1. Meta Learning algorithm to learn a corrector model on labels 
2. Corrector Model is design as such that it uses it's past correction, the current label estimation of the classifier and the actual label by doing convex combinations of them.
3. The weights of these combinations are the model and take as the input the difference (loss) between them.

<p align="center">

![MSLC](/figures/mslc-struct.png)

</p>

<!--truncate-->

## Assets

### Strengths

1. Reuses architecture and ideas from meta curriculum learning (MWNet) to do meta label correction.

### Drawbacks

1. The architecture of the corrector is weird, especially the $\beta$ part. If we are using it (we might not) why not learn with many more past $\tilde{y}^{t-k}$ with $k>1$.
2. Relies on a warm-up (competitors aren't).
3. Weirdly truncated experiments (noise ratio not going more than 0.4 for assymetric noise).

## Novelty

The approach is somewhat novel.

## Significance

The results are significant as the experiments have shown.

## Soudness

The paper seems OK.

## Evaluation

A lot of experiments have been conducted but on too few datasets and too few noise rates.

## How can I use/enhance the paper ?

## What did I learn from reading this paper ?

Smart use of old algorithm (MWNet) to another purpose.

## New paper to read/Interesting Citations

1. Training deep neural networks on noisy labels with bootstrapping

## How I am going to use this paper ?

Citation/Compare

## Bibtex

```
@article{wu2020learning,
  title={Learning to Purify Noisy Labels via Meta Soft Label Corrector},
  author={Wu, Yichen and Shu, Jun and Xie, Qi and Zhao, Qian and Meng, Deyu},
  journal={arXiv preprint arXiv:2008.00627},
  year={2020}
}
```