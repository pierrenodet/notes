---
title: "Meta Transition Adaptation for Robust Deep Learning with Noisy Labels"
---

<p align="center">

![MTAâ€™](/figures/mlc.png)

</p>

* **code** : ???
* **pdf** : https://arxiv.org/pdf/2006.05697.pdf

## Summary

1. Learning on biquality data thanks to a transition matrix.
2. Learns the transition matrix with meta learning as the main network is learning.

<!--truncate-->

## Assets

### Strengths

1. Smartly using meta learning to avoid hand made estimators
2. Plenty of Experiments

### Drawbacks

1. Initialization of the transition matrix seems important and costly (using GLC or Forward before applying this algorithm)

## Novelty

The paper is somewhat novel as it reuses known advances in meta learning on a well known algorithm biquality learning algorithm.

## Significance

The results are significant are the improvements in performance are huge and the estimation of the trensition matrix is way better.

## Soudness

The paper is technically sound with convergence proofs.

## Evaluation

The paper is very convincing with nice insights on why the method works better on suprising cases (better than classical cross-entropy on no noise)

## How can I use/enhance the paper ?

## What did I learn from reading this paper ?

Some insights on soft labels.

## New paper to read/Interesting Citations

## How I am going to use this paper ?

Implement it.

## Bibtex

```
@misc{shu2020meta,
      title={Meta Transition Adaptation for Robust Deep Learning with Noisy Labels}, 
      author={Jun Shu and Qian Zhao and Zongben Xu and Deyu Meng},
      year={2020},
      eprint={2006.05697},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```