<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="generator" content="Docusaurus">


<title data-react-helmet="true">Some proofs about statistical learning and label noise</title>

<meta data-react-helmet="true" http-equiv="x-ua-compatible" content="ie=edge"><meta data-react-helmet="true" property="og:title" content="Some proofs about statistical learning and label noise"><meta data-react-helmet="true" name="description" content="When doing binary classfication, having noise in our label means that they can be flipped from one class to the other. When observing a label, we will never know if it has been flipped or not, only the probability of the flip to occur."><meta data-react-helmet="true" property="og:description" content="When doing binary classfication, having noise in our label means that they can be flipped from one class to the other. When observing a label, we will never know if it has been flipped or not, only the probability of the flip to occur."><meta data-react-helmet="true" name="twitter:card" content="summary">

<link data-react-helmet="true" rel="shortcut icon" href="/thesis/img/favicon.ico">


<link rel="stylesheet" href="/thesis/styles.809cbcd8.css">

</head>
<body>

<div id="__docusaurus">
<nav class="navbar navbar--light navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a aria-current="page" class="navbar__brand active" href="/thesis/"><img class="navbar__logo" src="/thesis/img/logo.png" alt="thesis logo"><strong>thesis</strong></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/thesis/manuscript/introduction">Manuscript</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/thesis/notes">Reading Notes</a><a class="navbar__item navbar__link" target="_blank" rel="noopener noreferrer" href="https://github.com/pierrenodet/thesis">GitHub</a></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a aria-current="page" class="navbar__brand active" href="/thesis/"><img class="navbar__logo" src="/thesis/img/logo.png" alt="thesis logo"><strong>thesis</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/thesis/manuscript/introduction">Manuscript</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/thesis/notes">Reading Notes</a></li><li class="menu__list-item"><a class="menu__link" target="_blank" rel="noopener noreferrer" href="https://github.com/pierrenodet/thesis">GitHub</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="container margin-vert--xl"><div class="row"><div class="col col--8 col--offset-2"><article><header><h1 class="margin-bottom--sm blogPostTitle_2RZH">Some proofs about statistical learning and label noise</h1><div class="margin-bottom--sm"><time datetime="2020-01-11T00:00:00.000Z" class="blogPostDate_3tRe">January 11, 2020</time></div><div class="avatar margin-bottom--md"><div class="avatar__intro"></div></div></header><section class="markdown"><p>When doing binary classfication, having noise in our label means that they can be flipped from one class to the other. When observing a label, we will never know if it has been flipped or not, only the probability of the flip to occur.</p><p>Noisy labels can definitly mess up with model accuracy and make us unable to evaluate it. For example, answering this question can be quite hard : Is it a false positive or the algorithm was right and the label was flipped ?</p><p>Thanksfully researchers are clever and they found some theoritical guarantees to still be able to do machine learning in this setup. We will redo proofs found in various papers covering this subject, starting from the easiest setup (random noise) to the hardest one (individual dependent noise).</p><h2><a aria-hidden="true" tabindex="-1" class="anchor" id="notations"></a><a aria-hidden="true" tabindex="-1" class="hash-link" href="#notations" title="Direct link to heading">#</a>Notations</h2><p>Firts, let&#x27;s have some notations for the following proofs.</p><ul><li>Let $X \in \mathcal{X} \subset \mathbb{R}^d$, be the data</li><li>Let $Y \in \mathcal{Y} = {-1,+1}$, be the true unobserved label</li><li>Let $\tilde{Y} \in \mathcal{Y}$, be the observed labels</li><li>Let $D(X,Y)$, be the clean distribution</li><li>Let $D_ρ(X,\tilde{Y})$, be the noisy distribution</li><li>Let $ρ_Y(X) = \mathbb{P}(\tilde{Y}|Y,X)$, be the noise probability</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor" id="random-noise"></a><a aria-hidden="true" tabindex="-1" class="hash-link" href="#random-noise" title="Direct link to heading">#</a>Random Noise</h2><p>Having random noise in our labels means that the probability of a flip to occur is unrelated to the statsitical individual $X$ or from the label value $Y$.</p><p><strong>Definition :</strong></p><p>We say that our labels are under a random noise if there is $ρ∈\mathbb{R}$ so that $∀X∈\mathcal{X},∀Y∈\mathcal{Y}, ρ_Y(X)=ρ$</p><p><strong>Definition :</strong></p><ul><li>Let $\mathcal{F} = \mathcal{X}^{\mathcal{Y}}$</li><li>Let $L\in\mathcal{Y^2}^{\mathbb{R}}$</li><li>Let $c\in\mathbb{R}$</li></ul><p>We say that L is a symetric loss function when :</p><p>[
∀f∈\mathcal{F},∀x∈\mathcal{X},∑_{y\in\mathcal{Y}}L(f(x),y)=c
]</p><p><strong>Theorem :</strong></p><p>Let :</p><ul><li>$\mathcal{F} = \mathcal{X}^{\mathcal{Y}}$</li><li>$L\in\mathcal{Y^2}^{\mathbb{R}}$</li></ul><p>If :</p><ul><li>$\mathcal{Y}={-1,1}$</li><li>$L$ is a symetric loss function</li><li>$ρ∈\mathbb{R}$ and $ρ&lt;min_{y∈\mathcal{Y}}(\mathbb{P}(Y=y))$</li></ul><p>Then $L$ is robust to random noise :
[
argmin<em>{f∈\mathcal{F}}R</em>{D,L}(f)=argmin<em>{f∈\mathcal{F}}R</em>{D_ρ,L}(f)
]</p></section></article><div class="margin-vert--xl"><nav class="pagination-nav"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/thesis/notes/2019/09/27/zhou"><h5 class="pagination-nav__link--sublabel">Next Post</h5><h4 class="pagination-nav__link--label">Zhou - A Brief Introduction to Weakly Supervised Learning »</h4></a></div></nav></div></div></div></div></div><footer class="footer footer--dark"><div class="container"><div class="text--center">Copyright © 2020 Pierre Nodet.</div></div></footer>
</div>

<script src="/thesis/styles.e6a85e3a.js"></script>

<script src="/thesis/runtime~main.94082357.js"></script>

<script src="/thesis/main.f4e02dab.js"></script>

<script src="/thesis/common.43fcd4ce.js"></script>

<script src="/thesis/ccc49370.ac697eed.js"></script>

<script src="/thesis/0062fffe.d07b4fd8.js"></script>


</body>
</html>