<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://pierrenodet.github.io/</id>
    <title>notes Blog</title>
    <updated>2021-03-25T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://pierrenodet.github.io/"/>
    <subtitle>notes Blog</subtitle>
    <icon>https://pierrenodet.github.io/img/favicon.ico</icon>
    <rights>Copyright Â© 2021 Pierre Nodet.</rights>
    <entry>
        <title type="html"><![CDATA[Learning to Purify Noisy Labels via Meta Soft Label Corrector]]></title>
        <id>Learning to Purify Noisy Labels via Meta Soft Label Corrector</id>
        <link href="https://pierrenodet.github.io/notes/2021/03/25/mslc"/>
        <updated>2021-03-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[MSLC]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta Transition Adaptation for Robust Deep Learning with Noisy Labels]]></title>
        <id>Meta Transition Adaptation for Robust Deep Learning with Noisy Labels</id>
        <link href="https://pierrenodet.github.io/notes/2021/03/21/mta"/>
        <updated>2021-03-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[MTA]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels (MentorNet)]]></title>
        <id>MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels (MentorNet)</id>
        <link href="https://pierrenodet.github.io/notes/2021/03/01/mentornet"/>
        <updated>2021-03-01T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[MentorNet]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels (Co-teaching)]]></title>
        <id>Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels (Co-teaching)</id>
        <link href="https://pierrenodet.github.io/notes/2021/02/26/coteaching"/>
        <updated>2021-02-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Co-teaching]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting (MWNet)]]></title>
        <id>Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting (MWNet)</id>
        <link href="https://pierrenodet.github.io/notes/2021/02/24/mwnet"/>
        <updated>2021-02-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[MWNet]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta Label Correction for Noisy Label Learning (MLC)]]></title>
        <id>Meta Label Correction for Noisy Label Learning (MLC)</id>
        <link href="https://pierrenodet.github.io/notes/2021/02/19/mlc"/>
        <updated>2021-02-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[MLC]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flexible Biquality Learning with Mutual Information]]></title>
        <id>Flexible Biquality Learning with Mutual Information</id>
        <link href="https://pierrenodet.github.io/notes/2020/02/29/mutual-information"/>
        <updated>2020-02-29T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The concept of Biquality Data has been introduced in "Unifying Semi-Supervised and Robust Learning by Mixup" by Hataya and Nakayama where there is two sets of data, a trusted and an untrusted one.]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Importance Reweighting for Positive Unlabeled Learning]]></title>
        <id>Importance Reweighting for Positive Unlabeled Learning</id>
        <link href="https://pierrenodet.github.io/notes/2020/02/28/ir-pul"/>
        <updated>2020-02-28T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[After redoing the proofs of "Classification with Noisy Labels by Importance Reweighting" by Liu and Tao, we thought that extending their results to Positive Unlabeled Learning could be quite trivial and useful.]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some proofs about Statistical Learning and Label Noise]]></title>
        <id>Some proofs about Statistical Learning and Label Noise</id>
        <link href="https://pierrenodet.github.io/notes/2020/01/11/proofs"/>
        <updated>2020-01-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[When doing binary classfication, having noise in our label means that they can be flipped from one class to the other. When observing a label, we will never know if it has been flipped or not, only the probability of the flip to occur.]]></summary>
    </entry>
</feed>