(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{111:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/images/mlc-c349b4ef10e45681ad6f2384831d06ee.png"},68:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return i})),n.d(t,"metadata",(function(){return l})),n.d(t,"toc",(function(){return s})),n.d(t,"default",(function(){return b}));var a=n(3),r=n(7),o=(n(0),n(98)),i={title:"Meta Label Correction for Noisy Label Learning (MLC)",tags:["reading-notes","meta-learning","label-correction"]},l={permalink:"/notes/2021/02/19/mlc",editUrl:"https://github.com/pierrenodet/notes/edit/master/notes/2021-02-19-mlc.md",source:"@site/notes/2021-02-19-mlc.md",description:"MLC",date:"2021-02-19T00:00:00.000Z",tags:[{label:"reading-notes",permalink:"/notes/tags/reading-notes"},{label:"meta-learning",permalink:"/notes/tags/meta-learning"},{label:"label-correction",permalink:"/notes/tags/label-correction"}],title:"Meta Label Correction for Noisy Label Learning (MLC)",readingTime:3,truncated:!0,prevItem:{title:"Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting (MWNet)",permalink:"/notes/2021/02/24/mwnet"},nextItem:{title:"Flexible Biquality Learning with Mutual Information",permalink:"/notes/2020/02/29/mutual-information"}},s=[{value:"Assets",id:"assets",children:[{value:"Strengths",id:"strengths",children:[]},{value:"Drawbacks",id:"drawbacks",children:[]}]},{value:"Novelty",id:"novelty",children:[]},{value:"Significance",id:"significance",children:[]},{value:"Soudness",id:"soudness",children:[]},{value:"Evaluation",id:"evaluation",children:[]},{value:"How can I use/enhance the paper ?",id:"how-can-i-useenhance-the-paper-",children:[]},{value:"What did I learn from reading this paper ?",id:"what-did-i-learn-from-reading-this-paper-",children:[]},{value:"New paper to read/Interesting Citations",id:"new-paper-to-readinteresting-citations",children:[]},{value:"How I am going to use this paper ?",id:"how-i-am-going-to-use-this-paper-",children:[]},{value:"Bibtex",id:"bibtex",children:[]}],c={toc:s};function b(e){var t=e.components,i=Object(r.a)(e,["components"]);return Object(o.b)("wrapper",Object(a.a)({},c,i,{components:t,mdxType:"MDXLayout"}),Object(o.b)("p",{align:"center"},Object(o.b)("p",null,Object(o.b)("img",{alt:"MLC",src:n(111).default}))),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"code")," : ",Object(o.b)("a",{parentName:"li",href:"https://github.com/microsoft/MLC"},"https://github.com/microsoft/MLC")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"pdf")," : ",Object(o.b)("a",{parentName:"li",href:"https://www.microsoft.com/en-us/research/uploads/prod/2020/12/aaai2021_mlc_zheng.pdf"},"https://www.microsoft.com/en-us/research/uploads/prod/2020/12/aaai2021_mlc_zheng.pdf"))),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"MLC is an actual biquality learning algorithm (uses both trusted and untrusted data)."),Object(o.b)("li",{parentName:"ol"},"MLC uses a Meta Learning approach to correct corrupted/untrusted labels."),Object(o.b)("li",{parentName:"ol"},"The meta model (a label correction network) correct label for corrupted instances while the main model learns on corrected labels."),Object(o.b)("li",{parentName:"ol"},"Both models are jointly trained by solving bilevel optimization. The meta model is learned by how much the main model performs on trusted labels. The main model is learned by how much it performs on labels corrected by the meta model."),Object(o.b)("li",{parentName:"ol"},"A (novel) k step look ahead SGD to solve this optimization problem."),Object(o.b)("li",{parentName:"ol"},"Meta Model has an embedding of the data and the untrusted label as an input to learn how to correct it."),Object(o.b)("li",{parentName:"ol"},"Experiments on widely used datasets and noises against State-of-the-Art competitors.")),Object(o.b)("h2",{id:"assets"},"Assets"),Object(o.b)("h3",{id:"strengths"},"Strengths"),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"MLC uses untrusted samples by correcting their labels, works well on assymetrical noise"),Object(o.b)("li",{parentName:"ol"},"Meta Model has an embedding of the data and the untrusted label as an input to learn how to correct it."),Object(o.b)("li",{parentName:"ol"},"MLC and k-step look ahead SGD works well empirically.")),Object(o.b)("h3",{id:"drawbacks"},"Drawbacks"),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"Only agggregated results in experiments, hard to know when it's better than the competitors."),Object(o.b)("li",{parentName:"ol"},"Costly algorithm especially with at least 5 steps ahead SGD, experiments are made with pretrained embeddigns (ResNet/BERT)."),Object(o.b)("li",{parentName:"ol"},"Lack of theoritical guarantees (bilevel optimization heuristic only works empirically)."),Object(o.b)("li",{parentName:"ol"},"Less interpretable than competitors, for example GLC has an explicit transition matrix to correct labels, MLC use a MLP (blackbox) over embeddings of a resnet/bert."),Object(o.b)("li",{parentName:"ol"},"Correct Labels in an hard manner (don't use classifier confidence to do both label correction and instance reweighting)."),Object(o.b)("li",{parentName:"ol"},"Meta Learning algorithm (can be hard to implement for a wide spread of neural network architectures and optimizers). Thanksfully some library solve this problem (see higher for PyTorch).")),Object(o.b)("h2",{id:"novelty"},"Novelty"),Object(o.b)("p",null,"It\u2019s a Novel/Somewhat Novel approach that reapplies an idea found in another paper (mwnet) to learn how to relabel a noisy sample by using bilevel joint optimization. K step look ahead SGD might be novel too."),Object(o.b)("h2",{id:"significance"},"Significance"),Object(o.b)("p",null,"The results are moderately significant as the improvements in accuracy are not huge over GLC which is a way simpler algorithm to both implement, test and interpret (not a blackbox MLP to correct labels). Moreover the results in experiments are quite aggregated so it\u2019s not obvious where this method adds benefits (kind of label noise, strength of label noise, datasets)."),Object(o.b)("h2",{id:"soudness"},"Soudness"),Object(o.b)("p",null,"The soundness of the article seems ok as it reuses a lot of results found in other papers to justify the algorithm."),Object(o.b)("h2",{id:"evaluation"},"Evaluation"),Object(o.b)("p",null,"It's sufficient as it reuses a lot of ideas found in other papers and the reported performances seems ok."),Object(o.b)("h2",{id:"how-can-i-useenhance-the-paper-"},"How can I use/enhance the paper ?"),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"Combine both instance reweighting and label correction, by either combining MWNet and MLC or use the soft labels instead of hard labels provided by the meta model (the weight comes from the meta model confidence)."),Object(o.b)("li",{parentName:"ol"},"Doest it work well for not at random noise (it should but no experimentns have been conducted)")),Object(o.b)("h2",{id:"what-did-i-learn-from-reading-this-paper-"},"What did I learn from reading this paper ?"),Object(o.b)("p",null,"Better understanding of how meta learning works."),Object(o.b)("h2",{id:"new-paper-to-readinteresting-citations"},"New paper to read/Interesting Citations"),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"MWNet (predecessor)"),Object(o.b)("li",{parentName:"ol"},"DART (k-step look ahead SGD)")),Object(o.b)("h2",{id:"how-i-am-going-to-use-this-paper-"},"How I am going to use this paper ?"),Object(o.b)("p",null,"To implement."),Object(o.b)("h2",{id:"bibtex"},"Bibtex"),Object(o.b)("pre",null,Object(o.b)("code",{parentName:"pre"},"@article{zheng2021mlc,\n  title={Meta Label Correction for Noisy Label Learning},\n  author={Zheng, Guoqing and Awadallah, Ahmed Hassan and Dumais, Susan},  \n  journal={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={35},\n  year={2021},\n}\n")))}b.isMDXComponent=!0},98:function(e,t,n){"use strict";n.d(t,"a",(function(){return p})),n.d(t,"b",(function(){return u}));var a=n(0),r=n.n(a);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var c=r.a.createContext({}),b=function(e){var t=r.a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},p=function(e){var t=b(e.components);return r.a.createElement(c.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},m=r.a.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,i=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=b(n),m=a,u=p["".concat(i,".").concat(m)]||p[m]||d[m]||o;return n?r.a.createElement(u,l(l({ref:t},c),{},{components:n})):r.a.createElement(u,l({ref:t},c))}));function u(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var c=2;c<o;c++)i[c]=n[c];return r.a.createElement.apply(null,i)}return r.a.createElement.apply(null,n)}m.displayName="MDXCreateElement"}}]);