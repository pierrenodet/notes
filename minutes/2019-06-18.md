## Minutes for the June 18th weelky meeting

### Pierre Nodet présence à Agro ParisTech

27-28 juin -> 26-27 juillet
22-23 aout -> …

### 1er sujet : Premier sujet de Vincent

Un chapitre de thèse par grande catégories de ML appliquées à la fraude

Chapitre 1 : Classification supervisée avec classes déséquilibrées
Chapitre 2 : Detection d’outlier
Chapitre 3 : Active Learning

### 2ème sujet : Classification supervisée de données transactionnelles dans le cadre de la fraude

Ici les données transactionnelles ne sont pas des données temporelles :
Données transactionnelles -> Données temporelles non alignées et sparse -> Données temporelles alignées

Données transactionnelles : Deux tables dans une base relationnelle en relation 1-N

ID	Y
ID1	0
ID2	1
ID3	0

DO	RECEIVE	VALEUR
ID1	ID2	+1
ID1	ID3	+10
ID3	ID2	-5

Chapitre 1 : Fraudes à Orange point communs
	- motivation pour les données transactionnelles

Chapitre 2 : Impact des données transactionnelles
	- apprentissage d’une représentation

Chapitre 3 : Active Learning
	- comment faire de l’AL quand on doit construire une représentation ?
	- ref Slides Vincent

Chapitre 4 : Détection de drift sur des données transactionnelles
	- chercher une distance entre deux jeux de regèles MODL de construction de représentation (on analyse f(X) plutôt que P(y|X)
	- ref à l’ILP (inductive logic programming), SRL (statistical relational learning), MISERE (Prof)

Dans ce sujet on a du mal à voir le rapport avec la fraude (classification supervisée = on pert le côté inattendu)

On pourrait considérer nos labels 0 comme non fiables et nos labels 1 comme rares.
	- one class avec peu d’exemples ?
	- comment gérer les 0 non fiables (thèse Christophe Magrant)

On pourrait aussi regarder du côté du transfer learning (ref Dilan)
	- apprendre le plus rapidement possible un modèle

### 3ème sujet : Drift Forecasting

☠️

### 4ème sujet : Detection d’outlier sur des données transactionnelles

Détection d’outlier -> inattendu de la fraude -> nécessite de faire une hypothèse sur les données

Chapitre 1 : Anomalies sur des DT
Chapitre 2 : Detection de nouveauté
Chapitre 3 : Detection de Drift
Chapitre 4 : AL pour outlier (cf Vincent)

On a les mêmes hypothèses que dans le cas précédent (0 pas fiables, données déséquilibrées, …)

### 5ème sujet : AL pour la fraude et DT

Chapitre 1 : Calibration des probabilités
	- classes déséquilibrées
Chapitre 2 : AL et Feature Learning
	- slides Vincent
Chapitre 3 : Estimateur non biaisé de l’erreur généralisé
	- RF OOB
Chapitre 4 : Impact qualité des labels

### Pistes :

Problème de présélection des individus étiquetés (phénomène du survivant)

Problème de biais dans l’étiquetage (habitude de labélisation)

Comment nettoyer les outliers ? (Cf Romain Trinquart)

Regarder les travaux de Olivier Caelen (Orange Belgique, Chercheur sur la Fraude)

### Réfléchir à un sujet de stage qui aide la thèse
